#### 1 일차 작업:
- 데이터전처리와 pipeline으로 예측 : 0908_아플라톡신_데이터_분석_조상구_0909.ipynb
- 시계열자료 결측치 처리 예제 코드 : 09_09_timeseries_data_missing_imputation.ipynb
- 데이터를 다운사이징하여 예측하기 : 0908_아플라톡신_LIMS_데이터_분석_조상구_0909.ipynb
#### 2 일차 작업:
- target 값에서 아폴라톡시 검출값을 특정 수치(예, 0.0001)를 기준으로 이진 분류 데이터 변환 후 예측 : 0910_아플라톡신_데이터_분석_조상구.ipynb
- 기후 시계열정보를 바탕으로 CNN, LSTM, Transformer 등 3가지 딥러닝 적용 : 0910_아플라톡신_CNN_LSTM_조상구.ipynb
- -------------------------------------------------------------------------------------------------------------------

### 1차 결과 공유
#### As-IS 데이터로 예측하고 성능지표 해석 (Interpretation of Metrics)
- 높은 정확도 (Accuracy): 93%가 넘는 정확도는 모델이 전체적으로 예측을 잘하고 있는 것처럼 보이지만, 이는 대부분의 데이터가 속한 다수 클래스를 잘 맞히기 때문에 발생하는 착시 현상입니다.
- 낮은 재현율 (Recall): 평균 재현율이 0.5 이하로 매우 낮습니다. 이는 실제 긍정(Positive)인 데이터 중 모델이 찾아낸 비율이 절반도 되지 않는다는 의미입니다. 즉, 모델이 소수 클래스를 놓치고 있다는 뜻입니다.
- 낮은 정밀도 (Precision): 평균 정밀도가 0.03~0.04로 극도로 낮습니다. 이는 모델이 '긍정'이라고 예측한 것 중 실제로 '긍정'인 비율이 매우 낮다는 뜻입니다. 모델이 긍정이라고 예측할 때마다 대부분 틀린 예측을 하고 있다는 치명적인 문제입니다.
- 낮은 F1-점수 (F1-Score): F1-점수는 정밀도와 재현율의 조화평균으로, 이 두 지표가 모두 낮으므로 F1-점수도 매우 낮게 나타납니다. F1-점수가 낮다는 것은 모델이 소수 클래스를 예측하는 능력이 형편없다는 것을 의미합니다.

결론적으로, 이 모델은 다수 클래스만 집중적으로 예측하는 경향을 보이며, SMOTE의 효과가 미미하거나 오히려 모델의 혼동을 초래한 것으로 보입니다.

### 성능 개선 방안
#### 1. 데이터 다운사이징으로 부적합률이 높은 데이터로 예그하기
- 데이터를 다운사이징하여 이 코드로 : 0908_아플라톡신_LIMS_데이터_분석_조상구_0909.ipynb
- 데이터를 다운사이즈하면 0.4312% --> 0.4952 % 로 줄어들어 예측 모형 성능 향상 기대
- 추가로 검사유형을 고려하지 않고 식품유형의 부적합율이 0인 행을 모두 제거하면 데이터가 더 줄어들어(downsize) 부적합률이 높아지지 않을 까?

#### 2. 성능 개선 방안 (Suggestions for Improvement)
현재 모델의 낮은 재현율과 정밀도를 개선하기 위해 다음과 같은 방법을 고려할 수 있습니다.

##### 2.1. 데이터 샘플링 전략 재검토
- SMOTE-Tomek 또는 SMOTE-ENN 사용: 단순 SMOTE는 데이터의 경계에 있는 샘플을 정확히 처리하지 못할 수 있습니다. Tomek Link나 ENN(Edited Nearest Neighbors)과 같은 언더샘플링 기법을 SMOTE와 결합하면, 데이터 경계의 노이즈를 제거하여 모델의 학습을 돕습니다.
- ADASYN 또는 Borderline-SMOTE 사용: 이 기법들은 경계선(boundary)에 있는 소수 클래스 샘플을 더 많이 생성하여, 모델이 학습하기 어려운 영역에 더 집중할 수 있도록 돕습니다.

##### 2.2. 모델 및 하이퍼파라미터 튜닝
- 모델 교체: 현재 모델이 불균형 데이터에 적합하지 않을 수 있습니다. XGBoost, CatBoost와 같은 부스팅(Boosting) 계열 모델은 불균형 데이터에 비교적 강점을 보입니다.
- 클래스 가중치 (Class Weight) 적용: 모델 학습 시 소수 클래스에 더 높은 가중치를 부여하면, 모델이 소수 클래스의 오분류에 더 큰 패널티를 부여하게 되어 성능이 개선될 수 있습니다.  PyCaret의 tune_model 함수에서 class_weight='balanced'를 사용하거나, create_model 함수에서 scale_pos_weight와 같은 매개변수를 직접 설정할 수 있습니다.

##### 2.3. 새로운 변수 생성 및 선택
- 피처 엔지니어링: 기존 변수들을 조합하거나 가공하여 소수 클래스를 더 잘 구분할 수 있는 새로운 변수(Feature)를 만드세요.
- 피처 선택 (Feature Selection): 불필요한 변수를 제거하여 모델의 복잡성을 줄이고, 노이즈를 줄여 성능을 향상시킬 수 있습니다.
